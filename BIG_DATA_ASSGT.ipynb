{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freddykrugs/crime-arrest-prediction-bigdata/blob/main/BIG_DATA_ASSGT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ID5mE4ObecWe"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CrimeArrestPrediction\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "990dFuiuf-1d"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"ID\", LongType(), True),\n",
        "    StructField(\"Case Number\", StringType(), True),\n",
        "    StructField(\"Date\", StringType(), True),\n",
        "    StructField(\"Block\", StringType(), True),\n",
        "    StructField(\"IUCR\", StringType(), True),\n",
        "    StructField(\"Primary Type\", StringType(), True),\n",
        "    StructField(\"Description\", StringType(), True),\n",
        "    StructField(\"Location Description\", StringType(), True),\n",
        "    StructField(\"Arrest\", BooleanType(), True),\n",
        "    StructField(\"Domestic\", BooleanType(), True),\n",
        "    StructField(\"Beat\", IntegerType(), True),\n",
        "    StructField(\"District\", IntegerType(), True),\n",
        "    StructField(\"Ward\", IntegerType(), True),\n",
        "    StructField(\"Community Area\", IntegerType(), True),\n",
        "    StructField(\"FBI Code\", StringType(), True),\n",
        "    StructField(\"X Coordinate\", DoubleType(), True),\n",
        "    StructField(\"Y Coordinate\", DoubleType(), True),\n",
        "    StructField(\"Year\", IntegerType(), True),\n",
        "    StructField(\"Updated On\", StringType(), True),\n",
        "    StructField(\"Latitude\", DoubleType(), True),\n",
        "    StructField(\"Longitude\", DoubleType(), True),\n",
        "    StructField(\"Location\", StringType(), True)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GupVfaZzgCLQ"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(\n",
        "    file_path,\n",
        "    header=True,\n",
        "    schema=schema\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q--X6rtggTc5",
        "outputId": "19778448-4a49-4d79-ca4e-dcce39fb962a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: long (nullable = true)\n",
            " |-- Case Number: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Block: string (nullable = true)\n",
            " |-- IUCR: string (nullable = true)\n",
            " |-- Primary Type: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Location Description: string (nullable = true)\n",
            " |-- Arrest: boolean (nullable = true)\n",
            " |-- Domestic: boolean (nullable = true)\n",
            " |-- Beat: integer (nullable = true)\n",
            " |-- District: integer (nullable = true)\n",
            " |-- Ward: integer (nullable = true)\n",
            " |-- Community Area: integer (nullable = true)\n",
            " |-- FBI Code: string (nullable = true)\n",
            " |-- X Coordinate: double (nullable = true)\n",
            " |-- Y Coordinate: double (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Updated On: string (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            "\n",
            "+-------+-----------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+--------------------+\n",
            "|summary|               ID|       Case Number|                Date|         Block|              IUCR|     Primary Type|    Description|Location Description|              Beat|         District|              Ward|    Community Area|          FBI Code|      X Coordinate|      Y Coordinate|              Year|          Updated On|          Latitude|          Longitude|            Location|\n",
            "+-------+-----------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+--------------------+\n",
            "|  count|          8493086|           8493086|             8493086|       8493086|           8493086|          8493086|        8493086|             8477527|           8493086|          8493039|           7878267|           7879400|           8493086|           8398481|           8398481|           8493086|             8493086|           8398481|            8398481|             8398481|\n",
            "|   mean|7569918.186017191|          277222.5|                NULL|          NULL|1115.8052735362044|             NULL|           NULL|                NULL|1183.2151779694684|11.29548810502342| 22.78708566236712|37.371297560727974|11.578810971980909|1164665.4084354064|1885921.6893602544|2011.1226684858718|                NULL| 41.84256306573073| -87.67125280678115|                NULL|\n",
            "| stddev|3812088.572716885|155025.77649001902|                NULL|          NULL| 811.1014481030935|             NULL|           NULL|                NULL| 703.7654383171532| 6.96448204513234|13.859278216584686|21.546884826514514| 6.931603665636776| 16946.85227179838| 32422.81587163903| 7.160723337235951|                NULL|0.0892057439465568|0.06141508135067313|                NULL|\n",
            "|    min|              634|         01G050460|01/01/2001 01:00:...|0000X E 100 PL|              0110|            ARSON| $300 AND UNDER|\"CTA \"\"L\"\" PLATFORM\"|               111|                1|                 1|                 0|               01A|               0.0|               0.0|              2001|01/01/2007 07:32:...|      36.619446395|      -91.686565684|(36.619446395, -9...|\n",
            "|    max|         14106592|         ZZZ199957|12/31/2025 12:56:...|          XX S|              9901|WEAPONS VIOLATION|WIREROOM/SPORTS|                YMCA|              2535|               31|                50|                77|                26|         1205119.0|         1951622.0|              2026|12/31/2025 03:41:...|      42.022910333|      -87.524529378|(42.022910333, -8...|\n",
            "+-------+-----------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()\n",
        "df.count()\n",
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cDQiEF34ie7z"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5icgk6EHihRX",
        "outputId": "4df64099-7a56-4db6-e381-4d6310d4fd3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "| ID|Case Number|Date|Block|IUCR|Primary Type|Description|Location Description|Arrest|Domestic|Beat|District|  Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|Updated On|Latitude|Longitude|Location|\n",
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "|  0|          0|   0|    0|   0|           0|          0|               15559|     0|       0|   0|      47|614819|        613686|       0|       94605|       94605|   0|         0|   94605|    94605|   94605|\n",
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select([\n",
        "    sum(col(c).isNull().cast(\"int\")).alias(c)\n",
        "    for c in df.columns\n",
        "]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dTuShhlYpdrR"
      },
      "outputs": [],
      "source": [
        "parquet_path = \"/content/drive/MyDrive/crimes_parquet\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8mN9HmI7pjBF"
      },
      "outputs": [],
      "source": [
        "df.write \\\n",
        "  .mode(\"overwrite\") \\\n",
        "  .partitionBy(\"Year\") \\\n",
        "  .parquet(parquet_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLWt8AAOqYYF",
        "outputId": "bd9ea4c5-e41d-4897-c5b2-208433870541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8493086"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df = spark.read.parquet(parquet_path)\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m_jmjBONuOaK"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        "    \"Case Number\",\n",
        "    \"Updated On\",\n",
        "    \"Location\",\n",
        "    \"X Coordinate\",\n",
        "    \"Y Coordinate\"\n",
        "]\n",
        "\n",
        "df = df.drop(*columns_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8kNVW3_gyRXi"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import to_timestamp\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"Date\",\n",
        "    to_timestamp(\"Date\", \"MM/dd/yyyy hh:mm:ss a\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02qNvlLuyVKv",
        "outputId": "255e9d72-e53c-4411-d5f3-d215d709bd74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: long (nullable = true)\n",
            " |-- Date: timestamp (nullable = true)\n",
            " |-- Block: string (nullable = true)\n",
            " |-- IUCR: string (nullable = true)\n",
            " |-- Primary Type: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Location Description: string (nullable = true)\n",
            " |-- Arrest: boolean (nullable = true)\n",
            " |-- Domestic: boolean (nullable = true)\n",
            " |-- Beat: integer (nullable = true)\n",
            " |-- District: integer (nullable = true)\n",
            " |-- Ward: integer (nullable = true)\n",
            " |-- Community Area: integer (nullable = true)\n",
            " |-- FBI Code: string (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DI67Vy7_yYan"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import hour, dayofweek, month, when, col\n",
        "\n",
        "df = df.withColumn(\"Hour\", hour(\"Date\")) \\\n",
        "       .withColumn(\"DayOfWeek\", dayofweek(\"Date\")) \\\n",
        "       .withColumn(\"Month\", month(\"Date\")) \\\n",
        "       .withColumn(\n",
        "           \"IsWeekend\",\n",
        "           when(col(\"DayOfWeek\").isin([1,7]), 1).otherwise(0)\n",
        "       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SErx6s5zzLVa",
        "outputId": "60fb11f0-34af-46eb-c004-2e4d91e4b370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----+---------+-----+---------+\n",
            "|               Date|Hour|DayOfWeek|Month|IsWeekend|\n",
            "+-------------------+----+---------+-----+---------+\n",
            "|2002-01-03 06:00:00|   6|        5|    1|        0|\n",
            "|2002-02-05 22:30:00|  22|        3|    2|        0|\n",
            "|2002-01-18 16:45:00|  16|        6|    1|        0|\n",
            "|2002-02-07 07:45:00|   7|        5|    2|        0|\n",
            "|2002-01-31 23:55:00|  23|        5|    1|        0|\n",
            "+-------------------+----+---------+-----+---------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "df.select(\"Date\", \"Hour\", \"DayOfWeek\", \"Month\", \"IsWeekend\").show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3iFmvIcK5Jt6"
      },
      "outputs": [],
      "source": [
        "# Drop rows missing coordinates\n",
        "df = df.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
        "\n",
        "# Fill missing Ward & Community Area\n",
        "df = df.fillna({\n",
        "    \"Ward\": -1,\n",
        "    \"Community Area\": -1\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IncCysfO8Osu",
        "outputId": "46c414a2-1123-4f11-b4e7-134986925034"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8398481"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RXUqqKkZ9GQF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"label\", col(\"Arrest\").cast(\"integer\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8brpy7T9KyF",
        "outputId": "2706cf64-34da-4a35-ec30-5ccd8532640f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Arrest|label|\n",
            "+------+-----+\n",
            "| false|    0|\n",
            "| false|    0|\n",
            "|  true|    1|\n",
            "| false|    0|\n",
            "|  true|    1|\n",
            "+------+-----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "df.select(\"Arrest\", \"label\").show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sDbQj4tE_5o8"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"label\", col(\"Arrest\").cast(\"integer\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tHfn8ldMAAdY"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        "    \"ID\",\n",
        "    \"Block\",\n",
        "    \"Description\",\n",
        "    \"IUCR\",\n",
        "    \"FBI Code\",\n",
        "    \"Arrest\"\n",
        "]\n",
        "\n",
        "df = df.drop(*columns_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "u6-ePTw2AGHr"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7Rg2-Yp7AN_u"
      },
      "outputs": [],
      "source": [
        "categorical_cols = [\n",
        "    \"Primary Type\",\n",
        "    \"Location Description\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7_-L_kmCASgb"
      },
      "outputs": [],
      "source": [
        "indexers = [\n",
        "    StringIndexer(\n",
        "        inputCol=col,\n",
        "        outputCol=col + \"_index\",\n",
        "        handleInvalid=\"keep\"\n",
        "    )\n",
        "    for col in categorical_cols\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9-nf6SzvAWcZ"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(\n",
        "    inputCols=[col + \"_index\" for col in categorical_cols],\n",
        "    outputCols=[col + \"_vec\" for col in categorical_cols]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wvgj4nufAvqk"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-aRCbOoGAzMG"
      },
      "outputs": [],
      "source": [
        "numeric_cols = [\n",
        "    \"District\",\n",
        "    \"Community Area\",\n",
        "    \"Beat\",\n",
        "    \"Domestic\",\n",
        "    \"Hour\",\n",
        "    \"DayOfWeek\",\n",
        "    \"Month\",\n",
        "    \"IsWeekend\",\n",
        "    \"Latitude\",\n",
        "    \"Longitude\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "J7FQHcBwA3fT"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[col + \"_vec\" for col in categorical_cols] + numeric_cols,\n",
        "    outputCol=\"features\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoZifV7gBAh0",
        "outputId": "3c81833a-7df1-4330-bc07-fc1202d0896c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training count: 6718113\n",
            "Test count: 1680368\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(\"Training count:\", train_df.count())\n",
        "print(\"Test count:\", test_df.count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYbNMSPyDumY",
        "outputId": "09fdd55f-56e9-4e00-fedb-2255b5880b18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+\n",
            "|label|  count|\n",
            "+-----+-------+\n",
            "|    1|1691883|\n",
            "|    0|5026230|\n",
            "+-----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_df.groupBy(\"label\").count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDW2sgn4GEkw",
        "outputId": "868d6a61-53a9-46d1-c48f-fbbbff91fe0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+\n",
            "|label|  count|\n",
            "+-----+-------+\n",
            "|    1| 423638|\n",
            "|    0|1256730|\n",
            "+-----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_df.groupBy(\"label\").count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Rgas4MIp-Oh7"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import sum, col\n",
        "\n",
        "# Fill missing Location Description\n",
        "df = df.fillna({\n",
        "    \"Location Description\": \"Unknown\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nJXHkLFy_tyj"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=[\"District\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eAYQR1B_xbA",
        "outputId": "6a7de152-8d5c-43aa-a6d4-64d7bad1342c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training count: 6718078\n",
            "Test count: 1680356\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(\"Training count:\", train_df.count())\n",
        "print(\"Test count:\", test_df.count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NwoeoZYFA_oa"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Define categorical columns\n",
        "categorical_cols = [\n",
        "    \"Primary Type\",\n",
        "    \"Location Description\"\n",
        "]\n",
        "\n",
        "# Create indexers\n",
        "indexers = [\n",
        "    StringIndexer(\n",
        "        inputCol=col_name,\n",
        "        outputCol=col_name + \"_index\",\n",
        "        handleInvalid=\"keep\"\n",
        "    )\n",
        "    for col_name in categorical_cols\n",
        "]\n",
        "\n",
        "# Create encoder\n",
        "encoder = OneHotEncoder(\n",
        "    inputCols=[col_name + \"_index\" for col_name in categorical_cols],\n",
        "    outputCols=[col_name + \"_vec\" for col_name in categorical_cols]\n",
        ")\n",
        "\n",
        "# Define numeric columns\n",
        "numeric_cols = [\n",
        "    \"District\",\n",
        "    \"Community Area\",\n",
        "    \"Beat\",\n",
        "    \"Domestic\",\n",
        "    \"Hour\",\n",
        "    \"DayOfWeek\",\n",
        "    \"Month\",\n",
        "    \"IsWeekend\",\n",
        "    \"Latitude\",\n",
        "    \"Longitude\"\n",
        "]\n",
        "\n",
        "# Create assembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[col_name + \"_vec\" for col_name in categorical_cols] + numeric_cols,\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"keep\"\n",
        ")\n",
        "\n",
        "# Logistic Regression model\n",
        "lr = LogisticRegression(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    maxIter=20\n",
        ")\n",
        "\n",
        "# Build pipeline\n",
        "pipeline = Pipeline(\n",
        "    stages=indexers + [encoder, assembler, lr]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "lr_model = pipeline.fit(train_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qh0l2vYDBkm",
        "outputId": "5b50ca98-cf23-4db5-a5f2-e722cb15f4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 0.8706727366334376\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "predictions = lr_model.transform(test_df)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    metricName=\"areaUnderROC\"\n",
        ")\n",
        "\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9si22hFYGe-J",
        "outputId": "402d60f7-b148-4772-dd28-addb48bd14a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8657332136761495\n",
            "Precision: 0.8669323668040327\n",
            "Recall: 0.8657332136761495\n",
            "F1-score: 0.8540834306178485\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "accuracy_eval = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "precision_eval = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedPrecision\"\n",
        ")\n",
        "\n",
        "recall_eval = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedRecall\"\n",
        ")\n",
        "\n",
        "f1_eval = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")\n",
        "\n",
        "accuracy = accuracy_eval.evaluate(predictions)\n",
        "precision = precision_eval.evaluate(predictions)\n",
        "recall = recall_eval.evaluate(predictions)\n",
        "f1 = f1_eval.evaluate(predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x1_qPhtI8og",
        "outputId": "0e3ad127-32c2-4560-fd56-5de2659628f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-------+\n",
            "|label|prediction|  count|\n",
            "+-----+----------+-------+\n",
            "|    1|       0.0| 193049|\n",
            "|    0|       0.0|1223987|\n",
            "|    1|       1.0| 230753|\n",
            "|    0|       1.0|  32567|\n",
            "+-----+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.groupBy(\"label\", \"prediction\").count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "2Wh2gNImKIdR"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    numTrees=50,\n",
        "    maxDepth=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "rf_pipeline = Pipeline(\n",
        "    stages=indexers + [encoder, assembler, rf]\n",
        ")\n",
        "\n",
        "rf_model = rf_pipeline.fit(train_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKgcFYgpKQsn",
        "outputId": "1d46002a-6c31-4974-8685-fef7ecaedfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest ROC-AUC: 0.8666502071486141\n"
          ]
        }
      ],
      "source": [
        "rf_predictions = rf_model.transform(test_df)\n",
        "\n",
        "roc_auc_rf = evaluator.evaluate(rf_predictions)\n",
        "\n",
        "print(\"Random Forest ROC-AUC:\", roc_auc_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTdQsrHgUCqL",
        "outputId": "9f089632-a2be-4f3b-aa1a-fc5633fe3bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Accuracy: 0.8453482476332396\n",
            "RF Precision: 0.8696445802195975\n",
            "RF Recall: 0.8453482476332397\n",
            "RF F1-score: 0.8190155817534345\n"
          ]
        }
      ],
      "source": [
        "accuracy_rf = accuracy_eval.evaluate(rf_predictions)\n",
        "precision_rf = precision_eval.evaluate(rf_predictions)\n",
        "recall_rf = recall_eval.evaluate(rf_predictions)\n",
        "f1_rf = f1_eval.evaluate(rf_predictions)\n",
        "\n",
        "print(\"RF Accuracy:\", accuracy_rf)\n",
        "print(\"RF Precision:\", precision_rf)\n",
        "print(\"RF Recall:\", recall_rf)\n",
        "print(\"RF F1-score:\", f1_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNIfkawdUIyj",
        "outputId": "f4cf5d2b-7474-4ce7-9d92-87b5050532e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-------+\n",
            "|label|prediction|  count|\n",
            "+-----+----------+-------+\n",
            "|    1|       0.0| 257999|\n",
            "|    0|       0.0|1254683|\n",
            "|    1|       1.0| 165803|\n",
            "|    0|       1.0|   1871|\n",
            "+-----+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf_predictions.groupBy(\"label\", \"prediction\").count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_train = train_df.sample(fraction=0.3, seed=42)\n",
        "\n",
        "print(\"Sample training count:\", sample_train.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMlTgpzhJzET",
        "outputId": "11f7ed28-74e8-441d-c654-b53f2b57ebf9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample training count: 2017017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt = GBTClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    maxIter=20,\n",
        "    maxDepth=5,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "gbt_pipeline = Pipeline(\n",
        "    stages=indexers + [encoder, assembler, gbt]\n",
        ")\n",
        "\n",
        "gbt_model = gbt_pipeline.fit(sample_train)\n"
      ],
      "metadata": {
        "id": "vtl6Qw6zKBZ7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbt_predictions = gbt_model.transform(test_df)\n",
        "\n",
        "roc_auc_gbt = evaluator.evaluate(gbt_predictions)\n",
        "\n",
        "print(\"GBT ROC-AUC:\", roc_auc_gbt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtKoLsxdKE4I",
        "outputId": "9eaee64a-7f0b-4194-b444-90549510fb25"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBT ROC-AUC: 0.8711270960288389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_gbt = accuracy_eval.evaluate(gbt_predictions)\n",
        "precision_gbt = precision_eval.evaluate(gbt_predictions)\n",
        "recall_gbt = recall_eval.evaluate(gbt_predictions)\n",
        "f1_gbt = f1_eval.evaluate(gbt_predictions)\n",
        "\n",
        "print(\"GBT Accuracy:\", accuracy_gbt)\n",
        "print(\"GBT Precision:\", precision_gbt)\n",
        "print(\"GBT Recall:\", recall_gbt)\n",
        "print(\"GBT F1-score:\", f1_gbt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RVehCy-KLC8",
        "outputId": "cebc0a37-3115-4b15-d243-e168b94fd12e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBT Accuracy: 0.8712225266550659\n",
            "GBT Precision: 0.8789138729298276\n",
            "GBT Recall: 0.8712225266550659\n",
            "GBT F1-score: 0.8578116756891243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbt_predictions.groupBy(\"label\", \"prediction\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HqLRJ50KMAk",
        "outputId": "6f58635e-07ec-48d5-a581-9be36f53e3f2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-------+\n",
            "|label|prediction|  count|\n",
            "+-----+----------+-------+\n",
            "|    1|       0.0| 199951|\n",
            "|    0|       0.0|1240113|\n",
            "|    1|       1.0| 223851|\n",
            "|    0|       1.0|  16441|\n",
            "+-----+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n"
      ],
      "metadata": {
        "id": "NZm8_WnLkJXp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(lr.regParam, [0.0, 0.01, 0.1])\n",
        "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "             .build())\n"
      ],
      "metadata": {
        "id": "kPcHXL_VkMxe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossval = CrossValidator(\n",
        "    estimator=pipeline,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3,\n",
        "    parallelism=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "urF1TLd5kQTH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tune_train = train_df.sample(fraction=0.3, seed=42)\n",
        "\n",
        "print(\"Tuning dataset size:\", tune_train.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMamIUE4kecB",
        "outputId": "6f55041c-d3bc-490c-ec6a-cfa8eb8efe3a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning dataset size: 2017017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_model = crossval.fit(tune_train)\n"
      ],
      "metadata": {
        "id": "oiva5nkQk3jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr_model = cv_model.bestModel\n"
      ],
      "metadata": {
        "id": "3kIYaFPGkkuC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr = best_lr_model.stages[-1]\n",
        "\n",
        "print(\"Best regParam:\", best_lr.getRegParam())\n",
        "print(\"Best elasticNetParam:\", best_lr.getElasticNetParam())\n"
      ],
      "metadata": {
        "id": "10lrUm_kk_t1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428bf5d7-8d5d-47af-89fa-9becbf95c1f2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best regParam: 0.0\n",
            "Best elasticNetParam: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_predictions = best_lr_model.transform(test_df)\n",
        "\n",
        "roc_auc_tuned = evaluator.evaluate(tuned_predictions)\n",
        "\n",
        "accuracy_tuned = accuracy_eval.evaluate(tuned_predictions)\n",
        "precision_tuned = precision_eval.evaluate(tuned_predictions)\n",
        "recall_tuned = recall_eval.evaluate(tuned_predictions)\n",
        "f1_tuned = f1_eval.evaluate(tuned_predictions)\n",
        "\n",
        "print(\"Tuned ROC-AUC:\", roc_auc_tuned)\n",
        "print(\"Tuned Accuracy:\", accuracy_tuned)\n",
        "print(\"Tuned Precision:\", precision_tuned)\n",
        "print(\"Tuned Recall:\", recall_tuned)\n",
        "print(\"Tuned F1:\", f1_tuned)\n"
      ],
      "metadata": {
        "id": "XODFYly1Otg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8734f5-26ac-432d-9314-493f4cf4d917"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned ROC-AUC: 0.8705789938390706\n",
            "Tuned Accuracy: 0.8657558279317001\n",
            "Tuned Precision: 0.8669528420028717\n",
            "Tuned Recall: 0.8657558279317003\n",
            "Tuned F1: 0.854112464140273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(seed_value):\n",
        "\n",
        "    train_temp, test_temp = df.randomSplit([0.8, 0.2], seed=seed_value)\n",
        "\n",
        "    model = pipeline.fit(train_temp)\n",
        "    predictions_temp = model.transform(test_temp)\n",
        "\n",
        "    roc = evaluator.evaluate(predictions_temp)\n",
        "\n",
        "    return roc\n"
      ],
      "metadata": {
        "id": "IAWwRgy9oCl4"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_1 = evaluate_model(10)\n",
        "roc_2 = evaluate_model(20)\n",
        "roc_3 = evaluate_model(30)\n",
        "\n",
        "print(\"ROC 1:\", roc_1)\n",
        "print(\"ROC 2:\", roc_2)\n",
        "print(\"ROC 3:\", roc_3)\n",
        "\n",
        "mean_roc = (roc_1 + roc_2 + roc_3) / 3\n",
        "\n",
        "import math\n",
        "std_roc = math.sqrt(((roc_1 - mean_roc)**2 +\n",
        "                     (roc_2 - mean_roc)**2 +\n",
        "                     (roc_3 - mean_roc)**2) / 3)\n",
        "\n",
        "print(\"Mean ROC:\", mean_roc)\n",
        "print(\"Std Dev ROC:\", std_roc)\n"
      ],
      "metadata": {
        "id": "fbf-eOUPoFtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdb69e5-2b7b-4785-eead-936e20f85aa6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC 1: 0.871468789856865\n",
            "ROC 2: 0.8715095320213736\n",
            "ROC 3: 0.8711949287745907\n",
            "Mean ROC: 0.8713910835509431\n",
            "Std Dev ROC: 0.00013969610638002572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def timed_training(fraction):\n",
        "\n",
        "    subset = train_df.sample(fraction=fraction, seed=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model = pipeline.fit(subset)\n",
        "    end_time = time.time()\n",
        "\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    predictions = model.transform(test_df)\n",
        "    roc = evaluator.evaluate(predictions)\n",
        "\n",
        "    return duration, roc\n"
      ],
      "metadata": {
        "id": "EtQb6e8_vjaK"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_25, roc_25 = timed_training(0.25)\n",
        "time_50, roc_50 = timed_training(0.5)\n",
        "time_100, roc_100 = timed_training(1.0)\n",
        "\n",
        "print(\"25% - Time:\", time_25, \"ROC:\", roc_25)\n",
        "print(\"50% - Time:\", time_50, \"ROC:\", roc_50)\n",
        "print(\"100% - Time:\", time_100, \"ROC:\", roc_100)\n"
      ],
      "metadata": {
        "id": "t7TRXJSjvnTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b1dd42-376c-424b-aa7b-c78f20a35733"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25% - Time: 174.8285310268402 ROC: 0.8705699122049707\n",
            "50% - Time: 186.88108086585999 ROC: 0.8705883607838043\n",
            "100% - Time: 238.69779586791992 ROC: 0.8706729695179269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_stage = lr_model.stages[-1]\n",
        "\n",
        "coefficients = best_stage.coefficients\n",
        "intercept = best_stage.intercept\n",
        "\n",
        "print(\"Number of features:\", len(coefficients))\n",
        "print(\"Intercept:\", intercept)\n"
      ],
      "metadata": {
        "id": "iy8Kvkj77i5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd24f88-8378-415a-93ac-9889cd2c3a71"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 258\n",
            "Intercept: -32.77642481573792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = assembler.getInputCols()\n",
        "\n",
        "for name, coef in zip(feature_names, coefficients):\n",
        "    print(name, coef)\n"
      ],
      "metadata": {
        "id": "y9dpkDed7mri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49621f9-51f9-4e9c-c2d2-817ce3755bbd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primary Type_vec -1.495255690435285\n",
            "Location Description_vec -0.17885887053423954\n",
            "District -1.448728398721341\n",
            "Community Area 6.2078117821602286\n",
            "Beat -0.29602744295999744\n",
            "Domestic -0.21218264857574773\n",
            "Hour -1.4064708253833655\n",
            "DayOfWeek -1.2676389582907774\n",
            "Month -0.9923014607416903\n",
            "IsWeekend -1.3461975243253037\n",
            "Latitude 1.7638522754587238\n",
            "Longitude 2.232930967326232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_feature_names = numeric_cols\n",
        "\n",
        "numeric_coefs = coefficients[-len(numeric_cols):]\n",
        "\n",
        "for name, coef in zip(numeric_feature_names, numeric_coefs):\n",
        "    print(name, coef)\n"
      ],
      "metadata": {
        "id": "_GoV69FO8XOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd4230a-22a4-4257-8220-09189df708ed"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "District -0.01371088178643883\n",
            "Community Area -0.0014558517786160369\n",
            "Beat 0.00012246195900275124\n",
            "Domestic 0.33331409160203607\n",
            "Hour 0.0030291751020072805\n",
            "DayOfWeek -0.003703488115111709\n",
            "Month -0.0072528574861321984\n",
            "IsWeekend 0.015809468683874\n",
            "Latitude -0.05377717390768997\n",
            "Longitude -0.3868178983467636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.write().overwrite().save(\"/content/drive/MyDrive/final_lr_model\")\n"
      ],
      "metadata": {
        "id": "eFOqUC_X86eB"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/\")\n"
      ],
      "metadata": {
        "id": "E2vuV6u_9BBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90958a1e-ade3-4d81-bdab-84842467060e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Getting started.pdf',\n",
              " 'fluid_test[1].pdf',\n",
              " 'workshop_test[1].pdf',\n",
              " '18eng06019 maths exam.pdf',\n",
              " '18eng06019 EIS EXAM.pdf',\n",
              " '18ENG0619 DAVIES FREDRICK.pdf',\n",
              " 'MECHANICAL ENGINEERING 18ENG06019 MECHANICS.pdf',\n",
              " 'ENG DRAWING EXAM 18ENG06019.pdf',\n",
              " 'mechanical engineering 18eng06019 elect.pdf',\n",
              " 'FLUID COMPLAINT.pdf',\n",
              " 'structured programming complaint .pdf',\n",
              " '18ENG06019 (3).pdf',\n",
              " '18ENG06019 (2).pdf',\n",
              " '18ENG06019 (1).pdf',\n",
              " '18ENG06019.pdf',\n",
              " 'ENGMATHS 18ENG06019.xlsx',\n",
              " '18 ENG06 019.docx',\n",
              " 'Adobe Scan Feb 03, 2023.pdf',\n",
              " 'jamb admission letter .pdf',\n",
              " 'laptop receipt.pdf',\n",
              " 'zikora NIN',\n",
              " 'dumebi NIN',\n",
              " 'Fred NIN.pdf',\n",
              " 'Kosi NIN.pdf',\n",
              " 'Copy of Fred NIN.pdf',\n",
              " 'Photo from Fred',\n",
              " 'tech proof.jpeg',\n",
              " 'Untitled form (File responses)',\n",
              " 'Untitled form (1).gform',\n",
              " 'Untitled form.gform',\n",
              " 'Portfolio.pdf',\n",
              " 'vtu',\n",
              " 'introduction-to-graphics.pdf',\n",
              " 'Adobe Scan 16 Jan 2025.pdf',\n",
              " 'THE-ULTIMATE-SNIPE-GUIDE.pdf',\n",
              " 'Saved from Chrome',\n",
              " 'Transcript.pdf',\n",
              " 'reference letter .pdf',\n",
              " 'PERSONAL STATEMENT.pdf',\n",
              " 'Transaction_Receipt.pdf',\n",
              " 'Adobe Scan Jun 16, 2025.pdf',\n",
              " 'Statement of Purpose.pdf',\n",
              " 'Aca Transcript.pdf',\n",
              " 'Birth certificate',\n",
              " 'Neco.pdf',\n",
              " 'CAS-E4G2YQ9M59Z0T6-Davies.pdf',\n",
              " 'Proof of funds 22.pdf',\n",
              " 'Proof of funds 11.pdf',\n",
              " 'Certificate ABUAD.pdf',\n",
              " 'Share code.pdf',\n",
              " 'Itinerary (20).pdf',\n",
              " 'UKVI Decision.pdf',\n",
              " 'Reciept Folo',\n",
              " 'Back end certificate.pdf',\n",
              " 'Headshot.jpg',\n",
              " 'National insurance',\n",
              " 'CV.pdf',\n",
              " 'Current Account Statement (1).pdf',\n",
              " 'Address proof.pdf',\n",
              " 'FC Letter.docx',\n",
              " 'RTW SHARE CODE.pdf',\n",
              " 'Passport.pdf',\n",
              " 'Sales CV3.pdf',\n",
              " 'Carer CV.docx',\n",
              " 'COV Term Letter (1).pdf',\n",
              " 'NI.pdf',\n",
              " 'Current Account Statement.pdf',\n",
              " 'RTW Share code.pdf',\n",
              " 'Sales CV2.docx',\n",
              " 'Share code IND.pdf',\n",
              " 'Details to give your employer  GOV (1).UK.pdf',\n",
              " 'CLEAN CV.docx',\n",
              " 'Details to give your employer  GOV.UK.pdf',\n",
              " 'CAS3',\n",
              " 'CAS1',\n",
              " 'CAS2',\n",
              " 'DHL QR Code',\n",
              " 'CHEF CV.docx',\n",
              " 'Con CV2.docx',\n",
              " 'CV.docx',\n",
              " 'COV Term Letter.pdf',\n",
              " 'Colab Notebooks',\n",
              " 'cars.csv',\n",
              " 'Job Application Form BLANK 24.docx',\n",
              " 'Crimes_-_2001_to_Present (2).csv',\n",
              " 'crimes_parquet',\n",
              " 'final_lr_model']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp70Fl0gx1Cow6JAe8IPlE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}